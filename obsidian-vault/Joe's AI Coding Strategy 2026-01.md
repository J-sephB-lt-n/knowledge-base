---
created:
  - 2026-01-24T23:05
modified: 2026-01-28 14:33
tags:
type:
  - note
status:
  - in-progress
---
I was a skeptic for a very long time, but it's become clear to me that I need to embrace AI-generated coding and become an expert in it (while not losing the ability to think for myself).

I've been very convinced this month by these 3 approaches to AI coding:
1. https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents
2. [# Getting AI to Work in Complex Codebases (Dexter Horthy)](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md)
3. 

Facts I consider to be true:
(be careful if changing fact IDs here as these numbers are referenced later in this document)

| Fact ID | Fact                                                                                                                                                       | My confidence | Source                                                                                                   | Implication for coding agents                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1       | AI content is drowning in hype and marketing but there is real value for code generation (and learning)                                                    | HIGH          | My own experience                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 2       | If I delegate all knowledge to LLMs then my own skills will stagnate                                                                                       | HIGH          | My own experience                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 3       | All LLMs have a knowledge cutoff                                                                                                                           | HIGH          | Fundamental of the model architecture                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 4       | All LLMs base (pretraining) training data is primarily the public internet<br>(Anthropic also trained on millions of books, mostly pirated)                | MEDIUM        | - Common knowledge (e.g. common crawl)<br>- The big 2025 Anthropic law suit about pirated books          | - LLMs perform best at things that are commonly documented (e.g python vs zig). They are bad at niche tasks. i.e. use the most common technologies and standards (json, bash, git, react etc.)<br>- LLMs inherit bad habits (e.g. python bare try/except). Can mitigate with prompting (e.g. AGENTS.md)<br>- Magic words like "vertical slice architecture" or "Test-Driven Development" or "John Ousterhout" convey a lot of context to a LLM (drastically change their behaviour) |
| 5       | Coding AI agent products (e.g. Claude Code, Cursor, OpenAI codex) wrap the LLMs in a lot of their own custom prompting/tools/wrappers/ecosystem            | HIGH          |                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 6       | All LLMs are auto-regressive next token predictors                                                                                                         | HIGH          |                                                                                                          | - Ordering of information in the context window matters<br>- Place reasoning, motivation, discussion etc. before final decision or code generation.<br>- We can only control output quality through the content of the context window                                                                                                                                                                                                                                               |
| 7       | MCP, skills, subagents, background agents may or may not be useful                                                                                         |               |                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 8       | AI providers are running at a loss trying to capture market share                                                                                          | MEDIUM        |                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 9       | LLMs hallucinate and are convincing liars<br>(this is what they are trained to do)                                                                         | HIGH          | - Common knowledge<br>- My own experience                                                                | - to TDD<br>- agentic code reviewers                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| 10      | Generating reasoning traces improves performance on complex tasks                                                                                          | HIGH          | Documented in many studies                                                                               | Choose reasoning ("thinking") models for more complex coding tasks                                                                                                                                                                                                                                                                                                                                                                                                                  |
| 11      | Coding agents don't do long-term planning or architecture thinking                                                                                         | MEDIUM        | - My own experience                                                                                      | - This must be done for (and/or with) them<br>- Desired patterns must be documented and given to agents explicitly as context.<br>- Agents needs to be monitored to ensure they are complying with the architecture. Agent code reviewers?                                                                                                                                                                                                                                          |
| 12      | LLM are very good at using tools<br>(I'm sure they are fine-tuned for this)                                                                                | HIGH          | - My own experience                                                                                      | Give agents tools to use                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| 13      | A small number of good agent tools is better than many rubbish tools                                                                                       | HIGH          | - My own experience<br>- This was the original concept behind Claude Code (i.e. bash vs custom indexing) | It is worth investing a lot of time in iterating on a single agent tool                                                                                                                                                                                                                                                                                                                                                                                                             |
| 14      | More specific (unambiguous) and comprehensive prompts work result in better code                                                                           | HIGH          | - My own experience<br>- Common knowledge                                                                | - Work with a  template/framework which elicits good requirements (e.g. FURPS+)<br>- Use a chatbot to help refine prompts to make them more precise                                                                                                                                                                                                                                                                                                                                 |
| 15      | More relevant context leads to better code                                                                                                                 | HIGH          | - Common knowledge<br>- My own experience                                                                | Need to find an efficient way to manage context                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 16      | LLMs' broad pretraining makes them great for discussing/exploring different possible approaches to a problem                                               | HIGH          | My own experience                                                                                        | Have an explicit agent which involves brainstorming different possible approaches                                                                                                                                                                                                                                                                                                                                                                                                   |
| 17      | Structured reasoning (e.g. step-by-step reasoning, plan then execute, explain decisions, decompose into subproblems) improves performance on complex tasks | MEDIUM        |                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 18      | Different LLMs need different prompting approaches                                                                                                         | LOW           | - Picked this up online                                                                                  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 19      | Coding agents do better on small (tightly scoped) tasks than on large (loosely defined) ones                                                               | MEDIUM        |                                                                                                          | Break up big tasks into smaller tightly scoped ones                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| 20      | Iterative refinement works better than one-shot prompting                                                                                                  |               |                                                                                                          | - code review and QA (testing) agents<br>                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| 21      | Coding agents write code FAST.<br>Keeping the codebase under control is one of the biggest challenges.                                                     | HIGH          | - My own experience                                                                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 22      | Agents benefit from a clean environment                                                                                                                    | MEDIUM        | - My own experience                                                                                      | - If things are consistent in the codebase, then the agent can maintain that consistency (or be instructed to). i.e. we should make style, language, environment and architecture patterns explicit.<br>- The agent shouldn't need to waste tokens working out how to run the app/tests etc. correctly. Agent can fix this, or work it out then document it.                                                                                                                        |
| 23      | LLM agents are amazing at bash                                                                                                                             | HIGH          | - My own experience<br>- Claude Code                                                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 24      | It's hard to reason about and maintain a complex AI coding workflow<br>(e.g. multiple dependent agent slash commands with shared state)                    | MEDIUM        | - My own experience                                                                                      | - Keep things modular and simple                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 25      | Agents need to share state (context)                                                                                                                       | HIGH          | - Common sense                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 26      | LLMs are strong at language tasks (especially text generation)                                                                                             | HIGH          | - My own experience                                                                                      | - Use LLMs to review/improve prompts (e.g. "make this more precise", "apply LLM best practices")                                                                                                                                                                                                                                                                                                                                                                                    |
| 27      | What's in the context window is the only quality control we have                                                                                           | HIGH          |                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| 28      | LLM quality degrades as the context window fills up ("context rot")                                                                                        | HIGH          | - My own experience<br>- This is well documented, with supporting data                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |


## Proposed practices
(be careful if changing Practice IDs here as these numbers are referenced later in this document)

| Practice ID | Practice                                                                                                                                                         | Motivation/Notes                                                                                                                                                                                                                                       | Fact ID(s) |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------- |
| 1           | Store globally relevant context in `README.md` and `/docs/*.md` (e.g. `docs/PRD.md`)                                                                             | It's important to have a consistent place                                                                                                                                                                                                              | 25         |
| 2           | Store context relevant only to the current task in `.current_agent_context/*.md`                                                                                 | - It's important to have a consistent place.<br>- This needs to be cleaned out before starting a new task                                                                                                                                              | 25         |
| 3           | Break up large tasks into smaller ones                                                                                                                           | - Can write the list to `.current_agent_context/features_list.json` (each entry with `name`, `description`, `status`, `last_updated_at`)                                                                                                               |            |
| 4           | Make coding agents communicate through git logs and/or shared documents                                                                                          | PERSISTENT:<br>- `README.md`<br>- `docs/*.md`<br>- `docs/adr/<adr-num>-<adr-name>.md`<br>TEMPORARY:<br>-`.current_agent_context/developer_notes.json`<br>- `.current_agent_context/features_list.json`<br>- `.current_agent_context/useful_links.json` |            |
| 5           | Add observed repeat bad agent behaviour to AGENTS.md                                                                                                             |                                                                                                                                                                                                                                                        |            |
| 6           | Use a LLM to improve prompts before giving it to the coding agent                                                                                                |                                                                                                                                                                                                                                                        | 14, 15, 26 |
| 7           | Be aware of existing agent rules (e.g. .cursorrules, AGENTS.md, CLAUDE.md) in a brownfield codebase<br>(we must know exactly what is in the context window)      |                                                                                                                                                                                                                                                        | 6          |
| 8           | Always include in the prompt things like "please ask me clarifying questions if anything is unclear"                                                             | This helps to remove ambiguity in the LLM prompt                                                                                                                                                                                                       | 14         |
| 9           | Practice Test-Driven Development (TDD) wherever possible                                                                                                         | This helps make AI-generated code more testable and more trustworthy (this is not infallible)                                                                                                                                                          | 9          |
| 10          | Intentionally review AI-generated code<br>(manually and with review agents)                                                                                      | This should be done frequently (at every step)<br>- Ensure that generated code adheres to it's requirements<br>- Ensure that generated code adheres to existing patterns in the codebase<br>- Ensure that generated code                               | 10         |
| 11          | Create systems and frameworks for managing agent context (PRD, architecture design doc, README.md etc. etc.)<br>(don't forget that agent context includes tools) |                                                                                                                                                                                                                                                        |            |
| 12          | Instruct my coding agents to prompt me for what I know they need (explicit requirements, links to files for task context etc.)                                   | - This helps me to remember to give the LLM agent what it needs in order to do it's task well<br>- This is easy to include in agent slash commands                                                                                                     | 14         |
| 13          | Use subagents to preserve the context window                                                                                                                     |                                                                                                                                                                                                                                                        | 28         |

## Proposed coding agent workflow:
(putting all of )

| Step                                                                                                                                              | What it Does                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Practice ID(s) |
| ------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------- |
| **/discuss_potential_approaches**<br>(standalone task that can be run at any time, maybe just in ChatGPT web)                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                |
| **/discuss_codebase_architecture**<br>(greenfield: discuss->scaffold->document)<br>(brownfield: understand->document)                             | 1. Asks whether this is a green or brownfield codebase.<br>GREENFIELD:<br>- Asks me questions to work out desired  architecture characteristics<br>- We discuss possible architectures<br>- Scaffolds the files/folders<br>- Asks me where to document this (default is README.md)<br>BROWNFIELD:<br>- Identifies primary architecture characteristics and describes current architecture<br>- Asks me where to document this (default is README.md and/or docs/architecture_design.md) | 11             |
| **/discuss_prd**<br>(for greenfield coding task)<br>Create Product Requirements Document through a guided chat with a chatbot                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                |
| **/discuss_requirements**<br>(brownfield or small coding task)<br>Define requirements using a template/framework through guided chat with chatbot | 1. Asks me which of a preset list of requirements elicitation frameworks should be included<br>2. Asks me to describe the problem I'm trying to solve.<br>3. Runs me through each elicitation framework.<br>4. Organises the requirements gathered into a document and asks where it should save it.                                                                                                                                                                                    |                |
| **/gather_context**                                                                                                                               | 1. Asks me what we're gathering context on (optional: just give agent output of */discuss_requirements*)<br>2. Uses a research subagent to find all potentially relevant files.<br>3. Asks me which of the discovered files it should read.<br>4. Asks me direct questions if it is still missing required context.<br>5. Asks where this context should be written to (e.g. `.current_agent_context/<some-filename>.md`)                                                               |                |
| **/plan**                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 3              |
| **/write_code**                                                                                                                                   | 1. Asks what context I have for it (e.g. specific docs).<br>- Suggests `git log`, all files in `docs/**` and `.current_agent_context/*`<br>2. Asks permission to do TDD.<br>3. Asks whether we should run the application and see if it's working<br>4. Asks whether we should run the tests.<br>5. Asks where to write it's progress to after it's finished (it suggests `git log`, `.current_agent_context/*.md`, update `docs/*`).                                                   | 4, 12          |
| **/review_code_agent_generated**                                                                                                                  | - Checks agent-generated code adheres to existing application documentation <br>- Checks agent-generated code against specific predefined criteria                                                                                                                                                                                                                                                                                                                                      | 10             |
|                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                |






**Accepted practice:**
- Prompt for:
  - Input validation
  - Resource cleanup
  - Thread/process safety
  - Secure defaults (e.g., prepared statements, CSRF handling)

**Commonly accepted as true:**
- If you don’t explicitly ask for security and robustness, the agent often optimizes for “simple, illustrative code.”
- Security, error handling, and resilience improve when explicitly requested (or when your prompt includes internal security guidelines).

---

## 9. Use “review mode” and self-critique

**Accepted practice:**
- After getting code, ask the agent to:
  - Review it as if it were written by someone else
  - Identify possible bugs, edge cases, and performance issues
  - Suggest improvements without rewriting everything unnecessarily

**Commonly accepted as true:**
- Self-review prompts (or “critic then fix” loops) materially improve quality.
- Having the agent explain *why* the code is correct often surfaces hidden mistakes.

---

## 10. Ground the agent on real tools and feedback

**Accepted practice:**
- Combine AI with:
  - Compiler/interpreter errors
  - Static analysis (mypy, ESLint, flake8, SonarQube)
  - Test results
- Paste outputs back into the conversation and ask for fixes.

**Commonly accepted as true:**
- The best reliability comes from AI + automated tools + human review.
- When given real tool feedback, agents are much better at converging to correct, idiomatic solutions.

---

## 11. Use system / “role” instructions to set global behavior

**Accepted practice:**
- Establish up front:
  - “You are a senior backend engineer in Python.”
  - “Prioritize readability over micro-optimizations.”
  - “Never use network access; assume offline operation.”

**Commonly accepted as true:**
- Clear role + priorities at the start of the session improves consistency across many turns.
- It reduces the need to restate preferences in every prompt.

---

## 12. No prompt guarantees perfection; human review remains essential

**Accepted practice:**
- Always:
  - Review logic manually for important code
  - Run and extend tests
  - Inspect edge cases that weren’t considered
- Treat AI drafts as high-quality scaffolding, not final truth.

**Commonly accepted as true:**
- Even with excellent prompting, AI can:
  - Misinterpret ambiguous requirements
  - Produce subtly wrong logic
  - Use APIs incorrectly in edge cases
- “Guaranteed robust high-quality code” isn’t achievable solely via prompting; it requires verification.

---

If you want, I can turn these into a concrete “prompt template” you can reuse when asking coding agents for non-trivial features or refactors.


# Claude 4.5 Opus

# Commonly Accepted Facts About Prompting AI Coding Agents (as of 2025)

I should note that I can only speak to what's established through my knowledge cutoff in early 2025, not 2026. Here's what has become generally accepted:

## Widely Accepted Principles

**1. Specificity beats vagueness**
- Explicit constraints (language version, frameworks, error handling requirements) produce more reliable output than open-ended requests

**2. Examples work**
- Providing input/output examples or code style samples significantly improves consistency

**3. Decomposition helps**
- Breaking complex tasks into smaller, sequential prompts yields better results than single monolithic requests

**4. Context windows matter but aren't magic**
- More context helps, but relevant context beats large dumps of irrelevant code

**5. Verification is non-negotiable**
- No prompting technique *guarantees* robust, high-quality code—human review and testing remain essential

## What's Still Contested or Unclear

- Whether "chain of thought" prompting reliably improves code correctness
- Optimal prompt structure (there's no universal template that dominates)
- Whether persona prompts ("you are a senior engineer...") have real effects or are placebo

## Important Caveat

The phrase **"guaranteed robust high quality code"** remains aspirational, not achievable through prompting alone. The 2025 consensus is that prompting improves *probability* of good output, but testing, review, and iteration remain mandatory.

Would you like me to elaborate on any specific technique?

## References
* [Effective harnesses for long-running agents (Anthropic engineering blog)](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents)
## Related
* [No Vibes Allowed - Solving Hard Problems in Complex Codebases Dex Horthy HumanLayer (presentation at AI Engineer 2025)](No%20Vibes%20Allowed%20-%20Solving%20Hard%20Problems%20in%20Complex%20Codebases%20Dex%20Horthy%20HumanLayer%20(presentation%20at%20AI%20Engineer%202025).md)